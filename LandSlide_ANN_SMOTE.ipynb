{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OFAN5uNuWDdSkt-aIiSstktkFR6CwSsL",
      "authorship_tag": "ABX9TyN7PgV0upVNy8lFnyHmJpHp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirtha0809/Machine-Learning/blob/main/LandSlide_ANN_SMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ],
      "metadata": {
        "id": "Ve6g9aWWwlbD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a41kCAxwhbK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI8glgJqDLRp",
        "outputId": "cca26d2f-ee7a-4e15-faa1-678019c16937"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing the dataset"
      ],
      "metadata": {
        "id": "XAHovqWUwr72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/LANDSLIDE/Merged_World_LandslideData.csv')\n",
        "df.size"
      ],
      "metadata": {
        "id": "ogR7ZQ-zwuil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6debc034-3492-4acd-a422-d69489946281"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "755820"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Taking care of missing value"
      ],
      "metadata": {
        "id": "3TYf8Fz76vjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "sDnk8xea5yWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "LbP3S4dU1bjV",
        "outputId": "8d127aa4-058d-4478-be81-8650c202a5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Index  landslide_category  landslide_size  fatality_count  Latitude  \\\n",
              "0  1858.0                 7.0             2.0             0.0     16.92   \n",
              "1  1141.0                 6.0             2.0             4.0     30.38   \n",
              "4    55.0                 6.0             1.0             0.0     42.97   \n",
              "5  4000.0                 6.0             2.0             2.0     37.75   \n",
              "6  5609.0                 7.0             3.0             0.0     47.27   \n",
              "\n",
              "   Longitude  temp-2  temp-1  temp-0  maxt-2  ...  avgslope  LC_Type1_mean  \\\n",
              "0      73.59    26.3    26.5    26.2    27.7  ...    27.875       9.000000   \n",
              "1      78.09    26.7    27.2    25.8    28.1  ...    81.375       9.000000   \n",
              "4    -124.01    11.8     8.3     7.8    14.7  ...    88.875       1.000000   \n",
              "5     -25.20    14.0    14.1    15.8    17.0  ...   167.000       7.058824   \n",
              "6    -122.26    11.4    11.3    10.6    14.8  ...    40.000       6.764706   \n",
              "\n",
              "   LST_Day_1km_mean  NDVI_mean  NDWI_mean     aspect  elevation  \\\n",
              "0       15585.75010   0.276409   0.076935   85.79104       68.0   \n",
              "1       15080.14281   0.256626   0.161844  240.09620      828.0   \n",
              "4       14795.41238   0.490961   0.363601  173.99826       75.0   \n",
              "5       14609.53463   0.396181   0.306116   89.37942       68.0   \n",
              "6       14744.06481   0.352804   0.292128  110.89202       40.0   \n",
              "\n",
              "   precipitation_sum      slope  landslide_trigger  \n",
              "0        76083.62956  12.437977                1.0  \n",
              "1        49711.02632   3.715572                1.0  \n",
              "4        47384.80481  11.947599                1.0  \n",
              "5        20904.96219  56.214066                1.0  \n",
              "6        28623.51198  22.222166                1.0  \n",
              "\n",
              "[5 rows x 114 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-77dbe409-e22b-4a59-824e-3db3f6b72cec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>landslide_category</th>\n",
              "      <th>landslide_size</th>\n",
              "      <th>fatality_count</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>temp-2</th>\n",
              "      <th>temp-1</th>\n",
              "      <th>temp-0</th>\n",
              "      <th>maxt-2</th>\n",
              "      <th>...</th>\n",
              "      <th>avgslope</th>\n",
              "      <th>LC_Type1_mean</th>\n",
              "      <th>LST_Day_1km_mean</th>\n",
              "      <th>NDVI_mean</th>\n",
              "      <th>NDWI_mean</th>\n",
              "      <th>aspect</th>\n",
              "      <th>elevation</th>\n",
              "      <th>precipitation_sum</th>\n",
              "      <th>slope</th>\n",
              "      <th>landslide_trigger</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1858.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.92</td>\n",
              "      <td>73.59</td>\n",
              "      <td>26.3</td>\n",
              "      <td>26.5</td>\n",
              "      <td>26.2</td>\n",
              "      <td>27.7</td>\n",
              "      <td>...</td>\n",
              "      <td>27.875</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>15585.75010</td>\n",
              "      <td>0.276409</td>\n",
              "      <td>0.076935</td>\n",
              "      <td>85.79104</td>\n",
              "      <td>68.0</td>\n",
              "      <td>76083.62956</td>\n",
              "      <td>12.437977</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1141.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>30.38</td>\n",
              "      <td>78.09</td>\n",
              "      <td>26.7</td>\n",
              "      <td>27.2</td>\n",
              "      <td>25.8</td>\n",
              "      <td>28.1</td>\n",
              "      <td>...</td>\n",
              "      <td>81.375</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>15080.14281</td>\n",
              "      <td>0.256626</td>\n",
              "      <td>0.161844</td>\n",
              "      <td>240.09620</td>\n",
              "      <td>828.0</td>\n",
              "      <td>49711.02632</td>\n",
              "      <td>3.715572</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>42.97</td>\n",
              "      <td>-124.01</td>\n",
              "      <td>11.8</td>\n",
              "      <td>8.3</td>\n",
              "      <td>7.8</td>\n",
              "      <td>14.7</td>\n",
              "      <td>...</td>\n",
              "      <td>88.875</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14795.41238</td>\n",
              "      <td>0.490961</td>\n",
              "      <td>0.363601</td>\n",
              "      <td>173.99826</td>\n",
              "      <td>75.0</td>\n",
              "      <td>47384.80481</td>\n",
              "      <td>11.947599</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4000.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>37.75</td>\n",
              "      <td>-25.20</td>\n",
              "      <td>14.0</td>\n",
              "      <td>14.1</td>\n",
              "      <td>15.8</td>\n",
              "      <td>17.0</td>\n",
              "      <td>...</td>\n",
              "      <td>167.000</td>\n",
              "      <td>7.058824</td>\n",
              "      <td>14609.53463</td>\n",
              "      <td>0.396181</td>\n",
              "      <td>0.306116</td>\n",
              "      <td>89.37942</td>\n",
              "      <td>68.0</td>\n",
              "      <td>20904.96219</td>\n",
              "      <td>56.214066</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5609.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>47.27</td>\n",
              "      <td>-122.26</td>\n",
              "      <td>11.4</td>\n",
              "      <td>11.3</td>\n",
              "      <td>10.6</td>\n",
              "      <td>14.8</td>\n",
              "      <td>...</td>\n",
              "      <td>40.000</td>\n",
              "      <td>6.764706</td>\n",
              "      <td>14744.06481</td>\n",
              "      <td>0.352804</td>\n",
              "      <td>0.292128</td>\n",
              "      <td>110.89202</td>\n",
              "      <td>40.0</td>\n",
              "      <td>28623.51198</td>\n",
              "      <td>22.222166</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 114 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-77dbe409-e22b-4a59-824e-3db3f6b72cec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-77dbe409-e22b-4a59-824e-3db3f6b72cec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-77dbe409-e22b-4a59-824e-3db3f6b72cec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5d0fdb90-06cd-445d-9960-9346957e7bc7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5d0fdb90-06cd-445d-9960-9346957e7bc7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5d0fdb90-06cd-445d-9960-9346957e7bc7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz2mMReY5PTc",
        "outputId": "d01a6868-83e0-4c63-80b3-f1fcac83e747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "499092"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.iloc[:,1:-1].values\n",
        "y= df.iloc[:,-1].values\n",
        "smote= SMOTE(k_neighbors = 3)\n",
        "x_smote,y_smote = smote.fit_resample(x,y)"
      ],
      "metadata": {
        "id": "dEYWEKm06Fdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3_kLn8eTlgM",
        "outputId": "ee28e816-9ad3-43d8-f977-fc632e97943d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4378\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZ1s7xnP7R9k",
        "outputId": "a36a2a4f-6a50-43eb-f849-87c558168666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.00000000e+00 2.00000000e+00 0.00000000e+00 ... 6.80000000e+01\n",
            "  7.60836296e+04 1.24379770e+01]\n",
            " [6.00000000e+00 2.00000000e+00 4.00000000e+00 ... 8.28000000e+02\n",
            "  4.97110263e+04 3.71557240e+00]\n",
            " [6.00000000e+00 1.00000000e+00 0.00000000e+00 ... 7.50000000e+01\n",
            "  4.73848048e+04 1.19475990e+01]\n",
            " ...\n",
            " [1.00000000e+00 3.00000000e+00 0.00000000e+00 ... 4.36000000e+02\n",
            "  4.15912462e+04 2.72809580e+01]\n",
            " [7.00000000e+00 3.00000000e+00 0.00000000e+00 ... 2.35000000e+02\n",
            "  3.16836293e+04 1.38575620e+01]\n",
            " [6.00000000e+00 2.00000000e+00 0.00000000e+00 ... 1.40000000e+01\n",
            "  8.18185791e+04 8.16955600e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0Ab5_X99k0r",
        "outputId": "27104c9a-fde4-4aa1-e806-b9ebce052faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.  1.  1. ... 15. 15. 15.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ],
      "metadata": {
        "id": "ItKQ-24Q9kFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x_smote,y_smote,test_size = 0.33,random_state=0)"
      ],
      "metadata": {
        "id": "UP4h1DE_-QMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m789z7X-fWU",
        "outputId": "06c98b9e-021a-49ca-ed2b-8c8680a26c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.00000000e+00 2.00000000e+00 3.03200034e+00 ... 3.26079980e+02\n",
            "  7.54185452e+04 2.00218182e+01]\n",
            " [6.72388947e+00 2.27611053e+00 0.00000000e+00 ... 2.56955579e+02\n",
            "  4.94345672e+04 1.22241187e+01]\n",
            " [6.91264395e+00 2.73793186e+00 1.34942418e+00 ... 1.34850407e+02\n",
            "  5.94536659e+04 1.55561137e+01]\n",
            " ...\n",
            " [6.00000000e+00 2.00000000e+00 0.00000000e+00 ... 1.90943878e+03\n",
            "  1.03266706e+05 1.71851088e+01]\n",
            " [2.49125706e+00 2.00000000e+00 0.00000000e+00 ... 2.69283515e+02\n",
            "  4.43385524e+04 2.08071910e+01]\n",
            " [7.00000000e+00 2.00000000e+00 0.00000000e+00 ... 1.00500000e+03\n",
            "  1.31981817e+04 4.84394500e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcZhlTrw-fRM",
        "outputId": "3677d767-be1c-4c4e-8397-618b8e3ca747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.00000000e+01 2.00000000e+00 0.00000000e+00 ... 6.11000000e+02\n",
            "  6.58619721e+04 1.68027000e+01]\n",
            " [6.27184194e+00 2.00000000e+00 5.70868070e+00 ... 6.25950746e+02\n",
            "  4.29460532e+04 1.31410312e+01]\n",
            " [9.88960512e+00 2.96320171e+00 0.00000000e+00 ... 2.29473810e+02\n",
            "  2.42869024e+04 2.54396883e+01]\n",
            " ...\n",
            " [6.71607243e+00 2.14821730e+00 2.13571027e+00 ... 2.53776179e+02\n",
            "  5.99468060e+04 1.58552118e+01]\n",
            " [6.35670278e+00 2.35670278e+00 3.56702784e-01 ... 1.17431867e+03\n",
            "  6.85124605e+04 2.35512006e+01]\n",
            " [1.00000000e+00 2.00000000e+00 0.00000000e+00 ... 8.13000000e+02\n",
            "  2.15984626e+04 2.19791560e+01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFPA5WvI-fJz",
        "outputId": "187c73b5-10f4-4382-98e1-9845834edfa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13.  5.  7. ...  5.  6. 10.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0S1ZkjX-e1u",
        "outputId": "1545f4c5-f64d-4a41-d993-8c9230b96d69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2.  7. 11. ...  7.  7. 12.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Scaling"
      ],
      "metadata": {
        "id": "hPsh6a6H_Iw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "x_train = sc.fit_transform(x_train)\n",
        "x_test = sc.transform(x_test)"
      ],
      "metadata": {
        "id": "fgQ5D187_KPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvmsvQ8-APUk",
        "outputId": "2151bc92-17ab-43a7-b846-dfcfa47c0b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.44675564 -0.51082298  0.22176256 ... -0.43169331  1.11013931\n",
            "   0.3960939 ]\n",
            " [ 0.15466974  0.08763756 -0.21120096 ... -0.55310158  0.14413612\n",
            "  -0.41653508]\n",
            " [ 0.31149167  1.08862018 -0.01850592 ... -0.76756387  0.51661493\n",
            "  -0.06929476]\n",
            " ...\n",
            " [-0.44675564 -0.51082298 -0.21120096 ...  2.34927617  2.145447\n",
            "   0.10046924]\n",
            " [-3.36190656 -0.51082298 -0.21120096 ... -0.53144912 -0.04531781\n",
            "   0.47794069]\n",
            " [ 0.38406924 -0.51082298 -0.21120096 ...  0.76074384 -1.20301958\n",
            "  -1.18565204]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDmZmYwVAQXH",
        "outputId": "8be20bff-8922-49cb-fc6d-83272cf1e768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.87654388 -0.51082298 -0.21120096 ...  0.06873267  0.75485575\n",
            "   0.06061691]\n",
            " [-0.22090259 -0.51082298  0.6039871  ...  0.09499176 -0.09708658\n",
            "  -0.32098001]\n",
            " [ 2.78482506  1.57688519 -0.21120096 ... -0.60136983 -0.79077556\n",
            "   0.96071148]\n",
            " ...\n",
            " [ 0.14817516 -0.18956685  0.09377415 ... -0.5586858   0.53494834\n",
            "  -0.03812456]\n",
            " [-0.15039809  0.26231862 -0.16026453 ...  1.05813067  0.85339263\n",
            "   0.76390474]\n",
            " [-4.60088003 -0.51082298 -0.21120096 ...  0.42352012 -0.89072336\n",
            "   0.60007578]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_labels = np.unique(y_train)\n",
        "print(unique_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BR7oH3U8V0gF",
        "outputId": "d18be662-edbc-47a1-b2e7-891832aa63fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.  2.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have 14 unique classes\n",
        "num_classes = 14\n",
        "\n",
        "# Ensure class labels are within the valid range [0, num_classes-1]\n",
        "y_train_corrected = np.clip(y_train, 0, num_classes - 1)\n",
        "\n",
        "# Convert target labels to one-hot encoded format\n",
        "y_train_encoded = tf.keras.utils.to_categorical(y_train_corrected, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "f-mQlGg9V727"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building an ANN\n"
      ],
      "metadata": {
        "id": "KglIYDPsAnzv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the ANN"
      ],
      "metadata": {
        "id": "AZRbuzSlSzuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "4jqLvkI_ATM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding the input layer and the first hidden layer"
      ],
      "metadata": {
        "id": "FqOsm9h9THsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "nIG5KFOcTIuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding the second hidden layer"
      ],
      "metadata": {
        "id": "hfHXHmtOTSEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "Fq5iuVNeTYEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding the output layer"
      ],
      "metadata": {
        "id": "5BmTzTCVTc1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=num_classes,activation='softmax'))"
      ],
      "metadata": {
        "id": "qGuOYS7jTiT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3 - Training the ANN"
      ],
      "metadata": {
        "id": "vgqxylThEPR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the ANN"
      ],
      "metadata": {
        "id": "PsyIsMCdYb_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OB0-XQV5Av3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the ANN on the Training set"
      ],
      "metadata": {
        "id": "S0FWr1yNYsaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(x_train,y_train_encoded, batch_size =128, epochs =250)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bayL7QfxYyt_",
        "outputId": "66f69950-579b-4c1a-d8f0-82378e5bd1cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "164/164 [==============================] - 2s 4ms/step - loss: 2.5609 - accuracy: 0.1546\n",
            "Epoch 2/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 2.3204 - accuracy: 0.2839\n",
            "Epoch 3/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 2.0748 - accuracy: 0.3523\n",
            "Epoch 4/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.9099 - accuracy: 0.3714\n",
            "Epoch 5/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.8188 - accuracy: 0.3876\n",
            "Epoch 6/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.7569 - accuracy: 0.4018\n",
            "Epoch 7/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.7043 - accuracy: 0.4114\n",
            "Epoch 8/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.6548 - accuracy: 0.4292\n",
            "Epoch 9/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.6055 - accuracy: 0.4476\n",
            "Epoch 10/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.5636 - accuracy: 0.4573\n",
            "Epoch 11/250\n",
            "164/164 [==============================] - 0s 3ms/step - loss: 1.5325 - accuracy: 0.4653\n",
            "Epoch 12/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.5064 - accuracy: 0.4754\n",
            "Epoch 13/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.4828 - accuracy: 0.4826\n",
            "Epoch 14/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.4628 - accuracy: 0.4915\n",
            "Epoch 15/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.4439 - accuracy: 0.4997\n",
            "Epoch 16/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.4264 - accuracy: 0.5051\n",
            "Epoch 17/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.4096 - accuracy: 0.5111\n",
            "Epoch 18/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.3923 - accuracy: 0.5184\n",
            "Epoch 19/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.3764 - accuracy: 0.5258\n",
            "Epoch 20/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.3610 - accuracy: 0.5328\n",
            "Epoch 21/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.3467 - accuracy: 0.5344\n",
            "Epoch 22/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.3326 - accuracy: 0.5401\n",
            "Epoch 23/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.3196 - accuracy: 0.5459\n",
            "Epoch 24/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.3077 - accuracy: 0.5473\n",
            "Epoch 25/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.2963 - accuracy: 0.5548\n",
            "Epoch 26/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.2854 - accuracy: 0.5581\n",
            "Epoch 27/250\n",
            "164/164 [==============================] - 0s 3ms/step - loss: 1.2744 - accuracy: 0.5628\n",
            "Epoch 28/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.2663 - accuracy: 0.5659\n",
            "Epoch 29/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.2569 - accuracy: 0.5707\n",
            "Epoch 30/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.2502 - accuracy: 0.5735\n",
            "Epoch 31/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.2437 - accuracy: 0.5778\n",
            "Epoch 32/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.2357 - accuracy: 0.5813\n",
            "Epoch 33/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.2292 - accuracy: 0.5826\n",
            "Epoch 34/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.2222 - accuracy: 0.5885\n",
            "Epoch 35/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.2176 - accuracy: 0.5878\n",
            "Epoch 36/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.2115 - accuracy: 0.5934\n",
            "Epoch 37/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.2059 - accuracy: 0.5944\n",
            "Epoch 38/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.2003 - accuracy: 0.5990\n",
            "Epoch 39/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.1934 - accuracy: 0.6007\n",
            "Epoch 40/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.1893 - accuracy: 0.6032\n",
            "Epoch 41/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.1838 - accuracy: 0.6044\n",
            "Epoch 42/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.1787 - accuracy: 0.6081\n",
            "Epoch 43/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1733 - accuracy: 0.6080\n",
            "Epoch 44/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1704 - accuracy: 0.6103\n",
            "Epoch 45/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1660 - accuracy: 0.6128\n",
            "Epoch 46/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1608 - accuracy: 0.6133\n",
            "Epoch 47/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1578 - accuracy: 0.6124\n",
            "Epoch 48/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1522 - accuracy: 0.6163\n",
            "Epoch 49/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1502 - accuracy: 0.6152\n",
            "Epoch 50/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1455 - accuracy: 0.6183\n",
            "Epoch 51/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1412 - accuracy: 0.6205\n",
            "Epoch 52/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1375 - accuracy: 0.6194\n",
            "Epoch 53/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1353 - accuracy: 0.6230\n",
            "Epoch 54/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1316 - accuracy: 0.6220\n",
            "Epoch 55/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1282 - accuracy: 0.6249\n",
            "Epoch 56/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1270 - accuracy: 0.6241\n",
            "Epoch 57/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1235 - accuracy: 0.6263\n",
            "Epoch 58/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1198 - accuracy: 0.6270\n",
            "Epoch 59/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1167 - accuracy: 0.6289\n",
            "Epoch 60/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1133 - accuracy: 0.6292\n",
            "Epoch 61/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1121 - accuracy: 0.6310\n",
            "Epoch 62/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1079 - accuracy: 0.6316\n",
            "Epoch 63/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1055 - accuracy: 0.6341\n",
            "Epoch 64/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.1027 - accuracy: 0.6329\n",
            "Epoch 65/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0996 - accuracy: 0.6367\n",
            "Epoch 66/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0976 - accuracy: 0.6368\n",
            "Epoch 67/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0960 - accuracy: 0.6351\n",
            "Epoch 68/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0923 - accuracy: 0.6374\n",
            "Epoch 69/250\n",
            "164/164 [==============================] - 0s 3ms/step - loss: 1.0899 - accuracy: 0.6374\n",
            "Epoch 70/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0879 - accuracy: 0.6387\n",
            "Epoch 71/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0855 - accuracy: 0.6389\n",
            "Epoch 72/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0845 - accuracy: 0.6393\n",
            "Epoch 73/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0801 - accuracy: 0.6405\n",
            "Epoch 74/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0783 - accuracy: 0.6421\n",
            "Epoch 75/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0774 - accuracy: 0.6416\n",
            "Epoch 76/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0753 - accuracy: 0.6419\n",
            "Epoch 77/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0724 - accuracy: 0.6433\n",
            "Epoch 78/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0696 - accuracy: 0.6437\n",
            "Epoch 79/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0682 - accuracy: 0.6447\n",
            "Epoch 80/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0655 - accuracy: 0.6464\n",
            "Epoch 81/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0640 - accuracy: 0.6460\n",
            "Epoch 82/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0615 - accuracy: 0.6464\n",
            "Epoch 83/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0603 - accuracy: 0.6486\n",
            "Epoch 84/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0572 - accuracy: 0.6485\n",
            "Epoch 85/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0560 - accuracy: 0.6469\n",
            "Epoch 86/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.6489\n",
            "Epoch 87/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0528 - accuracy: 0.6500\n",
            "Epoch 88/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0507 - accuracy: 0.6513\n",
            "Epoch 89/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0491 - accuracy: 0.6510\n",
            "Epoch 90/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0484 - accuracy: 0.6512\n",
            "Epoch 91/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0478 - accuracy: 0.6515\n",
            "Epoch 92/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0450 - accuracy: 0.6509\n",
            "Epoch 93/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0441 - accuracy: 0.6521\n",
            "Epoch 94/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0433 - accuracy: 0.6523\n",
            "Epoch 95/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0409 - accuracy: 0.6525\n",
            "Epoch 96/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0389 - accuracy: 0.6547\n",
            "Epoch 97/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0389 - accuracy: 0.6531\n",
            "Epoch 98/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0371 - accuracy: 0.6546\n",
            "Epoch 99/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0348 - accuracy: 0.6549\n",
            "Epoch 100/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0322 - accuracy: 0.6567\n",
            "Epoch 101/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0330 - accuracy: 0.6561\n",
            "Epoch 102/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0306 - accuracy: 0.6555\n",
            "Epoch 103/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0295 - accuracy: 0.6576\n",
            "Epoch 104/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0267 - accuracy: 0.6583\n",
            "Epoch 105/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0268 - accuracy: 0.6582\n",
            "Epoch 106/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0249 - accuracy: 0.6584\n",
            "Epoch 107/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0235 - accuracy: 0.6576\n",
            "Epoch 108/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0241 - accuracy: 0.6576\n",
            "Epoch 109/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0218 - accuracy: 0.6586\n",
            "Epoch 110/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0213 - accuracy: 0.6592\n",
            "Epoch 111/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0202 - accuracy: 0.6581\n",
            "Epoch 112/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0195 - accuracy: 0.6594\n",
            "Epoch 113/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0161 - accuracy: 0.6610\n",
            "Epoch 114/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0146 - accuracy: 0.6619\n",
            "Epoch 115/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0138 - accuracy: 0.6607\n",
            "Epoch 116/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0152 - accuracy: 0.6613\n",
            "Epoch 117/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0087 - accuracy: 0.6631\n",
            "Epoch 118/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0106 - accuracy: 0.6630\n",
            "Epoch 119/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0088 - accuracy: 0.6619\n",
            "Epoch 120/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 1.0078 - accuracy: 0.6632\n",
            "Epoch 121/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 1.0043 - accuracy: 0.6636\n",
            "Epoch 122/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0042 - accuracy: 0.6638\n",
            "Epoch 123/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0035 - accuracy: 0.6633\n",
            "Epoch 124/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0019 - accuracy: 0.6630\n",
            "Epoch 125/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 1.0017 - accuracy: 0.6634\n",
            "Epoch 126/250\n",
            "164/164 [==============================] - 0s 3ms/step - loss: 0.9991 - accuracy: 0.6644\n",
            "Epoch 127/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9989 - accuracy: 0.6650\n",
            "Epoch 128/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9982 - accuracy: 0.6655\n",
            "Epoch 129/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9963 - accuracy: 0.6647\n",
            "Epoch 130/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9938 - accuracy: 0.6661\n",
            "Epoch 131/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9937 - accuracy: 0.6665\n",
            "Epoch 132/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9944 - accuracy: 0.6655\n",
            "Epoch 133/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9939 - accuracy: 0.6659\n",
            "Epoch 134/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.6671\n",
            "Epoch 135/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9897 - accuracy: 0.6674\n",
            "Epoch 136/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9878 - accuracy: 0.6681\n",
            "Epoch 137/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9893 - accuracy: 0.6674\n",
            "Epoch 138/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9877 - accuracy: 0.6674\n",
            "Epoch 139/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9869 - accuracy: 0.6679\n",
            "Epoch 140/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9867 - accuracy: 0.6679\n",
            "Epoch 141/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9854 - accuracy: 0.6688\n",
            "Epoch 142/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9840 - accuracy: 0.6685\n",
            "Epoch 143/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9860 - accuracy: 0.6690\n",
            "Epoch 144/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9814 - accuracy: 0.6702\n",
            "Epoch 145/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9823 - accuracy: 0.6691\n",
            "Epoch 146/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9800 - accuracy: 0.6701\n",
            "Epoch 147/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9794 - accuracy: 0.6711\n",
            "Epoch 148/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9796 - accuracy: 0.6708\n",
            "Epoch 149/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9796 - accuracy: 0.6707\n",
            "Epoch 150/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9772 - accuracy: 0.6709\n",
            "Epoch 151/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9759 - accuracy: 0.6713\n",
            "Epoch 152/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9782 - accuracy: 0.6715\n",
            "Epoch 153/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9738 - accuracy: 0.6725\n",
            "Epoch 154/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9727 - accuracy: 0.6730\n",
            "Epoch 155/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9733 - accuracy: 0.6729\n",
            "Epoch 156/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9720 - accuracy: 0.6737\n",
            "Epoch 157/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9714 - accuracy: 0.6737\n",
            "Epoch 158/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9724 - accuracy: 0.6718\n",
            "Epoch 159/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9721 - accuracy: 0.6735\n",
            "Epoch 160/250\n",
            "164/164 [==============================] - 0s 3ms/step - loss: 0.9719 - accuracy: 0.6746\n",
            "Epoch 161/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9685 - accuracy: 0.6735\n",
            "Epoch 162/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9674 - accuracy: 0.6724\n",
            "Epoch 163/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9680 - accuracy: 0.6747\n",
            "Epoch 164/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9653 - accuracy: 0.6742\n",
            "Epoch 165/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9639 - accuracy: 0.6752\n",
            "Epoch 166/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9636 - accuracy: 0.6750\n",
            "Epoch 167/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9623 - accuracy: 0.6748\n",
            "Epoch 168/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9620 - accuracy: 0.6760\n",
            "Epoch 169/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9617 - accuracy: 0.6746\n",
            "Epoch 170/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9607 - accuracy: 0.6750\n",
            "Epoch 171/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9622 - accuracy: 0.6752\n",
            "Epoch 172/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9600 - accuracy: 0.6772\n",
            "Epoch 173/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9571 - accuracy: 0.6767\n",
            "Epoch 174/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9563 - accuracy: 0.6772\n",
            "Epoch 175/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9580 - accuracy: 0.6755\n",
            "Epoch 176/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9560 - accuracy: 0.6757\n",
            "Epoch 177/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9542 - accuracy: 0.6780\n",
            "Epoch 178/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9554 - accuracy: 0.6760\n",
            "Epoch 179/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9533 - accuracy: 0.6771\n",
            "Epoch 180/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9527 - accuracy: 0.6772\n",
            "Epoch 181/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9517 - accuracy: 0.6773\n",
            "Epoch 182/250\n",
            "164/164 [==============================] - 0s 3ms/step - loss: 0.9532 - accuracy: 0.6769\n",
            "Epoch 183/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9513 - accuracy: 0.6782\n",
            "Epoch 184/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9513 - accuracy: 0.6789\n",
            "Epoch 185/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9488 - accuracy: 0.6788\n",
            "Epoch 186/250\n",
            "164/164 [==============================] - 1s 5ms/step - loss: 0.9485 - accuracy: 0.6789\n",
            "Epoch 187/250\n",
            "164/164 [==============================] - 1s 6ms/step - loss: 0.9468 - accuracy: 0.6784\n",
            "Epoch 188/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9463 - accuracy: 0.6784\n",
            "Epoch 189/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9460 - accuracy: 0.6785\n",
            "Epoch 190/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9490 - accuracy: 0.6770\n",
            "Epoch 191/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9444 - accuracy: 0.6787\n",
            "Epoch 192/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9443 - accuracy: 0.6789\n",
            "Epoch 193/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9431 - accuracy: 0.6798\n",
            "Epoch 194/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9429 - accuracy: 0.6784\n",
            "Epoch 195/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9419 - accuracy: 0.6792\n",
            "Epoch 196/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9417 - accuracy: 0.6784\n",
            "Epoch 197/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9395 - accuracy: 0.6788\n",
            "Epoch 198/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9390 - accuracy: 0.6786\n",
            "Epoch 199/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9400 - accuracy: 0.6784\n",
            "Epoch 200/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9392 - accuracy: 0.6788\n",
            "Epoch 201/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9382 - accuracy: 0.6790\n",
            "Epoch 202/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9378 - accuracy: 0.6796\n",
            "Epoch 203/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9385 - accuracy: 0.6788\n",
            "Epoch 204/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9371 - accuracy: 0.6785\n",
            "Epoch 205/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9364 - accuracy: 0.6799\n",
            "Epoch 206/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9379 - accuracy: 0.6790\n",
            "Epoch 207/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9354 - accuracy: 0.6791\n",
            "Epoch 208/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9351 - accuracy: 0.6794\n",
            "Epoch 209/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9329 - accuracy: 0.6806\n",
            "Epoch 210/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9326 - accuracy: 0.6798\n",
            "Epoch 211/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9333 - accuracy: 0.6798\n",
            "Epoch 212/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9331 - accuracy: 0.6797\n",
            "Epoch 213/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9330 - accuracy: 0.6783\n",
            "Epoch 214/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9308 - accuracy: 0.6799\n",
            "Epoch 215/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9304 - accuracy: 0.6804\n",
            "Epoch 216/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9329 - accuracy: 0.6803\n",
            "Epoch 217/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9305 - accuracy: 0.6805\n",
            "Epoch 218/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9287 - accuracy: 0.6798\n",
            "Epoch 219/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9268 - accuracy: 0.6807\n",
            "Epoch 220/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9267 - accuracy: 0.6815\n",
            "Epoch 221/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9279 - accuracy: 0.6808\n",
            "Epoch 222/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9260 - accuracy: 0.6813\n",
            "Epoch 223/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9266 - accuracy: 0.6814\n",
            "Epoch 224/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9257 - accuracy: 0.6816\n",
            "Epoch 225/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9260 - accuracy: 0.6808\n",
            "Epoch 226/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9269 - accuracy: 0.6796\n",
            "Epoch 227/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9266 - accuracy: 0.6817\n",
            "Epoch 228/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9224 - accuracy: 0.6820\n",
            "Epoch 229/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9232 - accuracy: 0.6810\n",
            "Epoch 230/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9233 - accuracy: 0.6809\n",
            "Epoch 231/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9226 - accuracy: 0.6809\n",
            "Epoch 232/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9198 - accuracy: 0.6822\n",
            "Epoch 233/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9218 - accuracy: 0.6805\n",
            "Epoch 234/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9218 - accuracy: 0.6817\n",
            "Epoch 235/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9191 - accuracy: 0.6815\n",
            "Epoch 236/250\n",
            "164/164 [==============================] - 1s 4ms/step - loss: 0.9210 - accuracy: 0.6808\n",
            "Epoch 237/250\n",
            "164/164 [==============================] - 1s 3ms/step - loss: 0.9184 - accuracy: 0.6815\n",
            "Epoch 238/250\n",
            "164/164 [==============================] - 0s 3ms/step - loss: 0.9185 - accuracy: 0.6824\n",
            "Epoch 239/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9183 - accuracy: 0.6823\n",
            "Epoch 240/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9178 - accuracy: 0.6816\n",
            "Epoch 241/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9168 - accuracy: 0.6816\n",
            "Epoch 242/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9170 - accuracy: 0.6823\n",
            "Epoch 243/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9162 - accuracy: 0.6831\n",
            "Epoch 244/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9159 - accuracy: 0.6829\n",
            "Epoch 245/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9186 - accuracy: 0.6818\n",
            "Epoch 246/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9145 - accuracy: 0.6838\n",
            "Epoch 247/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9151 - accuracy: 0.6832\n",
            "Epoch 248/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9140 - accuracy: 0.6832\n",
            "Epoch 249/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9128 - accuracy: 0.6827\n",
            "Epoch 250/250\n",
            "164/164 [==============================] - 0s 2ms/step - loss: 0.9142 - accuracy: 0.6823\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x786c141e1840>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###predict\n"
      ],
      "metadata": {
        "id": "jDT2FVpT5Hmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure class labels in y_test are within the valid range [0, num_classes-1]\n",
        "y_test_corrected = np.clip(y_test, 0, num_classes - 1)\n",
        "\n",
        "# Convert y_test to one-hot encoded format\n",
        "y_test_encoded = tf.keras.utils.to_categorical(y_test_corrected, num_classes=num_classes)\n",
        "\n",
        "y_pred = ann.predict(x_test)\n",
        "# Print the concatenated array\n",
        "concatenated_array = np.concatenate((y_pred, y_test_encoded), axis=1)\n",
        "np.set_printoptions(precision=2, suppress=True)  # Set formatting options\n",
        "print(concatenated_array)\n"
      ],
      "metadata": {
        "id": "2RMozAv35LOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64915152-f08c-4787-f8b0-6f07815a2cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "322/322 [==============================] - 1s 1ms/step\n",
            "[[0.   0.42 0.11 ... 0.   0.   0.  ]\n",
            " [0.   0.01 0.   ... 0.   0.   0.  ]\n",
            " [0.   0.   0.01 ... 1.   0.   0.  ]\n",
            " ...\n",
            " [0.   0.01 0.   ... 0.   0.   0.  ]\n",
            " [0.   0.02 0.   ... 0.   0.   0.  ]\n",
            " [0.   0.   0.   ... 0.   1.   0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Making the Confusion Matrix"
      ],
      "metadata": {
        "id": "g7NdXJISEhLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "mse = mean_squared_error(y_test_encoded, y_pred)\n",
        "mae = mean_absolute_error(y_test_encoded, y_pred)\n",
        "r2 = r2_score(y_test_encoded, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"R-squared:\", r2)\n"
      ],
      "metadata": {
        "id": "KPO5Upg9EjI-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c221d279-4e1c-4431-83d8-4661f1a404e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.03224468\n",
            "Mean Absolute Error: 0.0644878\n",
            "R-squared: 0.45788996236976026\n"
          ]
        }
      ]
    }
  ]
}