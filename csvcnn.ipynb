{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMt7dh01s4lNQyLWLjkYrkl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tirtha0809/Machine-Learning/blob/main/csvcnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from keras.layers import Dense, Conv3D, Flatten, Dropout, MaxPooling3D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "VRO5s6nkStFa"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hasXCJSSfIMh",
        "outputId": "8845142c-bdb1-4581-f571-5a855d9d6593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "   Index  landslide_category  landslide_size  fatality_count  Latitude  \\\n",
            "0   1858                   7               2               0     16.92   \n",
            "1   1141                   6               2               4     30.38   \n",
            "2    689                  10               2               0     37.41   \n",
            "3   2056                   6               2               1      4.58   \n",
            "4     55                   6               1               0     42.97   \n",
            "\n",
            "   Longitude  temp-2  temp-1  temp-0  maxt-2  ...  avgslope  LC_Type1_mean  \\\n",
            "0      73.59    26.3    26.5    26.2    27.7  ...    27.875            9.0   \n",
            "1      78.09    26.7    27.2    25.8    28.1  ...    81.375            9.0   \n",
            "2     -82.44    14.3    17.8    20.1    18.7  ...    90.125            8.0   \n",
            "3     101.39    24.5    25.8    26.2    26.0  ...    86.625            9.0   \n",
            "4    -124.01    11.8     8.3     7.8    14.7  ...    88.875            1.0   \n",
            "\n",
            "   LST_Day_1km_mean  NDVI_mean  NDWI_mean     aspect  elevation  \\\n",
            "0       15585.75010   0.276409   0.076935   85.79104         68   \n",
            "1       15080.14281   0.256626   0.161844  240.09620        828   \n",
            "2       14752.95843   0.221603   0.157116  240.72006        214   \n",
            "3       14897.02571   0.309143   0.277579  116.49185       1363   \n",
            "4       14795.41238   0.490961   0.363601  173.99826         75   \n",
            "\n",
            "   precipitation_sum      slope  landslide_trigger  \n",
            "0        76083.62956  12.437977                  1  \n",
            "1        49711.02632   3.715572                  1  \n",
            "2        33773.52943  21.662153                  1  \n",
            "3        83529.08578   6.213272                  1  \n",
            "4        47384.80481  11.947599                  1  \n",
            "\n",
            "[5 rows x 114 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 6622 entries, 0 to 6621\n",
            "Columns: 114 entries, Index to landslide_trigger\n",
            "dtypes: float64(98), int64(16)\n",
            "memory usage: 5.8 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the CSV file\n",
        "try:\n",
        "    df = pd.read_csv('/content/drive/MyDrive/LANDSLIDE/LandslideData2.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: CSV file not found. Please check the file path.\")\n",
        "    exit()\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred while loading CSV file: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Data Exploration\n",
        "print(df.head())  # Display the first few rows of the DataFrame\n",
        "print(df.info())  # Get information about column names, data types, and missing values\n",
        "\n",
        "\n",
        "\n",
        "# Encode categorical variables\n",
        "# Note: Assuming 'category' is the target column\n",
        "X = df.drop('landslide_trigger', axis=1)\n",
        "y = df['landslide_trigger']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Reshape the data for the 2D CNN model\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1], 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train)"
      ],
      "metadata": {
        "id": "-gX8dvHsU7n5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b11f2b-67b9-434a-edd8-6eb436803f59"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[-0.74234902]\n",
            "   [-0.21484918]\n",
            "   [-0.36395779]\n",
            "   ...\n",
            "   [-0.4492186 ]\n",
            "   [ 0.61418462]\n",
            "   [-1.16224696]]]\n",
            "\n",
            "\n",
            " [[[ 1.41618947]\n",
            "   [-3.57392856]\n",
            "   [ 1.3854836 ]\n",
            "   ...\n",
            "   [-0.25493262]\n",
            "   [-0.5872355 ]\n",
            "   [-1.0111159 ]]]\n",
            "\n",
            "\n",
            " [[[ 1.03827582]\n",
            "   [-0.21484918]\n",
            "   [ 1.3854836 ]\n",
            "   ...\n",
            "   [-0.72201741]\n",
            "   [-0.18538243]\n",
            "   [-0.92199992]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[ 0.38409427]\n",
            "   [-0.21484918]\n",
            "   [-0.36395779]\n",
            "   ...\n",
            "   [ 1.71986463]\n",
            "   [ 0.82392283]\n",
            "   [ 1.48346104]]]\n",
            "\n",
            "\n",
            " [[[ 0.10469881]\n",
            "   [-0.21484918]\n",
            "   [-0.36395779]\n",
            "   ...\n",
            "   [-0.51176272]\n",
            "   [-0.53200602]\n",
            "   [ 0.42335043]]]\n",
            "\n",
            "\n",
            " [[[ 0.28401231]\n",
            "   [-0.21484918]\n",
            "   [-0.36395779]\n",
            "   ...\n",
            "   [ 0.19618347]\n",
            "   [ 0.26697454]\n",
            "   [ 1.47417697]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = tf.keras.Input(shape = (5304, 1, 113, 1))"
      ],
      "metadata": {
        "id": "co_Gk2zEVf1x"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tf.convert_to_tensor(X_train)"
      ],
      "metadata": {
        "id": "WK2k3A5_Wkg7"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyS0cocmW26Y",
        "outputId": "7084f3ce-7f26-4f1e-8d05-b4424c674a04"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([5297, 1, 113, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Reshape input data to include channel dimension\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_test = np.expand_dims(X_test, axis=-1)\n",
        "\n",
        "# Verify the shape after reshaping\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Mpzz8ibbMW",
        "outputId": "63009e05-568a-481f-b0b8-740d648ca264"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (5297, 1, 113, 1, 1)\n",
            "Shape of X_test: (1325, 1, 113, 1, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "\n",
        "# Reshape the input data to match the expected shape for Conv1D\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[2], X_train.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[2], X_test.shape[1])\n",
        "\n",
        "# Define the input shape excluding the batch size dimension\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, kernel_size=3, activation='relu', input_shape=input_shape))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(14, activation='softmax'))  # Adjust num_classes based on your problem\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "AS95jmxAW0Xq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aef92433-d052-44e4-897d-3345d2d50d6f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_18 (Conv1D)          (None, 111, 32)           128       \n",
            "                                                                 \n",
            " max_pooling1d_13 (MaxPooli  (None, 55, 32)            0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " conv1d_19 (Conv1D)          (None, 53, 64)            6208      \n",
            "                                                                 \n",
            " max_pooling1d_14 (MaxPooli  (None, 26, 64)            0         \n",
            " ng1D)                                                           \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 1664)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               213120    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 14)                1806      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 221262 (864.30 KB)\n",
            "Trainable params: 221262 (864.30 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of y_train:\", y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IQ8bih5jXK2",
        "outputId": "5ade268f-9135-4696-b983-541bd4808bc4"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_train: (5297, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)"
      ],
      "metadata": {
        "id": "28tqlAXujiHv"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes_train = len(np.unique(y_train))\n",
        "num_classes_test = len(np.unique(y_test))\n",
        "\n",
        "print(f\"Number of classes in y_train: {num_classes_train}\")\n",
        "print(f\"Number of classes in y_test: {num_classes_test}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pls8WMcxj5fJ",
        "outputId": "41821a0f-60a9-4daf-cbdd-b57211221643"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes in y_train: 2\n",
            "Number of classes in y_test: 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: train and evaluate\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Loss:\", loss)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 809
        },
        "id": "afPLktpojnhe",
        "outputId": "6bc5cddf-d435-4275-92cd-c1d8d7d1bbdd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 15, 2) and (None, 14) are incompatible\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-28b52aeca3ee>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 15, 2) and (None, 14) are incompatible\n"
          ]
        }
      ]
    }
  ]
}